# Production Docker Compose Configuration
# All environment variables MUST be set in .env (no fallbacks for secrets)
#
# REQUIRED in .env:
#   - JWT_SECRET (32+ chars)
#   - JWT_REFRESH_SECRET (32+ chars)
#   - POSTGRES_PASSWORD (use strong password!)
#   - NEXT_PUBLIC_SITE_URL (your production domain, e.g., https://example.com)
#   - NEXT_PUBLIC_API_URL (your production API URL, e.g., https://api.example.com)
#   - ADMIN_SEED_PASSWORD (for initial admin, or leave empty to auto-generate)
#
# Run: docker-compose -f docker-compose.prod.yml up -d

services:
  client:
    build:
      context: ./client
      dockerfile: Dockerfile
      additional_contexts:
        - shared=./shared
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:?NEXT_PUBLIC_API_URL is required for production}
        - NEXT_PUBLIC_SITE_URL=${NEXT_PUBLIC_SITE_URL:?NEXT_PUBLIC_SITE_URL is required for production}
        - NEXT_PUBLIC_SITE_NAME=${NEXT_PUBLIC_SITE_NAME:-Perfumes Store}
        - NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=${NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY}
    ports:
      - "${CLIENT_PORT:-3000}:3000"
    environment:
      - NODE_ENV=production
      - API_URL=http://server:4000
      # NEXT_PUBLIC_* vars are needed at runtime for SSR
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL}
      - NEXT_PUBLIC_SITE_URL=${NEXT_PUBLIC_SITE_URL}
      - NEXT_PUBLIC_SITE_NAME=${NEXT_PUBLIC_SITE_NAME:-Perfumes Store}
      - NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY=${NEXT_PUBLIC_STRIPE_PUBLISHABLE_KEY}
    depends_on:
      server:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - perfumes-prod-network
    labels:
      - "com.perfumesstore.service=client"
      - "com.perfumesstore.environment=production"
      - "com.perfumesstore.description=Next.js frontend application"
      - "com.perfumesstore.port=3000"
      - "com.perfumesstore.version=1.0"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  server:
    build:
      context: ./server
      dockerfile: Dockerfile
      additional_contexts:
        - shared=./shared
      args:
        - PLATFORM=${PLATFORM:-linux}
    ports:
      - "${SERVER_PORT:-4000}:4000"
    environment:
      - NODE_ENV=production
      - PORT=4000
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_REFRESH_SECRET=${JWT_REFRESH_SECRET}
      - ADMIN_SEED_PASSWORD=${ADMIN_SEED_PASSWORD:-}
      - CLIENT_URL=${NEXT_PUBLIC_SITE_URL:?NEXT_PUBLIC_SITE_URL is required for production}
      - BACKEND_URL=${NEXT_PUBLIC_API_URL:?NEXT_PUBLIC_API_URL is required for production}
      - STRIPE_SECRET_KEY=${STRIPE_SECRET_KEY}
      - STRIPE_WEBHOOK_SECRET=${STRIPE_WEBHOOK_SECRET}
      - COOKIE_DOMAIN=${COOKIE_DOMAIN:-}
      - RESEND_API_KEY=${RESEND_API_KEY:-}
      - RESEND_FROM_EMAIL=${RESEND_FROM_EMAIL:-}
    volumes:
      - ./server/uploads:/app/uploads
    depends_on:
      postgres:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/api/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - perfumes-prod-network
    labels:
      - "com.perfumesstore.service=server"
      - "com.perfumesstore.environment=production"
      - "com.perfumesstore.description=Express.js API backend"
      - "com.perfumesstore.port=4000"
      - "com.perfumesstore.version=1.0"
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  postgres:
    image: postgres:16-alpine
    environment:
      - POSTGRES_USER=${POSTGRES_USER:?POSTGRES_USER is required for production}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:?POSTGRES_PASSWORD is required for production}
      - POSTGRES_DB=${POSTGRES_DB:?POSTGRES_DB is required for production}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    # NOTE: No ports exposed in production - access only via internal Docker network
    # For database maintenance, use: docker-compose exec postgres psql -U $POSTGRES_USER -d $POSTGRES_DB
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER}"]
      interval: 5s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - perfumes-prod-network
    labels:
      - "com.perfumesstore.service=database"
      - "com.perfumesstore.environment=production"
      - "com.perfumesstore.description=PostgreSQL database"
      - "com.perfumesstore.port=5432"
      - "com.perfumesstore.version=16"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 2G
        reservations:
          cpus: '0.25'
          memory: 1G

  # Automated database backups
  # Runs pg_dump daily and keeps 7 days of backups
  postgres-backup:
    image: postgres:16-alpine
    environment:
      - PGHOST=postgres
      - PGUSER=${POSTGRES_USER}
      - PGPASSWORD=${POSTGRES_PASSWORD}
      - PGDATABASE=${POSTGRES_DB}
      - BACKUP_RETENTION_DAYS=${BACKUP_RETENTION_DAYS:-7}
    volumes:
      - postgres_backups:/backups
    depends_on:
      postgres:
        condition: service_healthy
    # Run backup script every day at 2 AM
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        # Install required utilities
        apk add --no-cache dcron

        # Create backup script
        cat > /backup.sh << 'BACKUP_SCRIPT'
        #!/bin/sh
        set -e
        TIMESTAMP=$$(date +%Y%m%d_%H%M%S)
        BACKUP_FILE="/backups/backup_$${TIMESTAMP}.sql.gz"

        echo "[$$TIMESTAMP] Starting database backup..."
        pg_dump -Fc | gzip > "$$BACKUP_FILE"
        echo "[$$TIMESTAMP] Backup completed: $$BACKUP_FILE"

        # Remove backups older than retention period
        echo "[$$TIMESTAMP] Cleaning old backups (keeping last $${BACKUP_RETENTION_DAYS} days)..."
        find /backups -name "backup_*.sql.gz" -mtime +$${BACKUP_RETENTION_DAYS} -delete

        # List remaining backups
        echo "[$$TIMESTAMP] Current backups:"
        ls -lh /backups/backup_*.sql.gz 2>/dev/null || echo "No backups found"
        BACKUP_SCRIPT

        chmod +x /backup.sh

        # Add cron job (daily at 2 AM)
        echo "0 2 * * * /backup.sh >> /var/log/backup.log 2>&1" | crontab -

        # Run initial backup on startup
        echo "Running initial backup..."
        /backup.sh

        # Start cron daemon in foreground
        echo "Starting backup scheduler (daily at 2 AM)..."
        crond -f -l 2
    restart: unless-stopped
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
        max-file: "2"
    networks:
      - perfumes-prod-network
    labels:
      - "com.perfumesstore.service=backup"
      - "com.perfumesstore.environment=production"
      - "com.perfumesstore.description=PostgreSQL automated backup service"
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M

volumes:
  postgres_data:
  postgres_backups:

networks:
  perfumes-prod-network:
    driver: bridge
    ipam:
      driver: default
      config:
        - subnet: 172.30.0.0/16
          gateway: 172.30.0.1
